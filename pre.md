## **方案 1：把检测改成“点监督”自训练（Box → Center/Point）**

  **核心想法**：小目标的框标注贵且噪声大，但“中心点/热力图”更稳。

做法是让 Teacher 在无标注图上产出**中心点伪标签**（甚至不需要框），Student 学“找点”，再把点反推成框（或只训练 objectness+center，再弱化 box 回归）。

- 无标注损失：中心热力图一致性（弱增强 vs 强增强）、点的位置一致性
    
- 监督数据：有框时把框中心当点（或者用高斯热图）
    
- 优点：小目标尤其有效，因为框回归对小目标太敏感（1–2 像素就崩），点监督更抗噪
    

> 工程上你可以：额外加一个 center-head（像 keypoint head），或在现有 head 上用 objectness map 的峰值当点。

---

## **方案 2：多尺度特征蒸馏（不是蒸馏框，而是蒸馏 P2/P3 特征图）**

**核心想法**：伪框不准没关系，让 Student 在无标注图上直接“长得像”Teacher 的小目标特征。

特别对小目标，**P2/P3（高分辨率特征层）**最关键。

- Teacher(EMA) 给无标注图输出多尺度特征 F_t^{P2,P3}
    
- Student 在强增强图上输出 F_s^{P2,P3}，做对齐（注意增强的几何变换要同步/可逆）
    
- 损失：$L_feat = Σ || stopgrad(F_t) - F_s ||（$L2/Huber/余弦都行）
    
- 叠加少量伪标签框训练即可（甚至伪框很少也能起效）
    

  

**为什么算创新**：你不再被“伪框质量”卡死，而是用“表征一致性”把小目标能力先灌进去。

---

## **方案 3：面积自适应的“分布式框回归”（把 box 当概率分布学）**

**核心想法**：小目标框回归不确定性很大，硬回归很容易被错伪标签带偏。

让 Teacher 输出框的**分布/不确定性**，Student 去拟合这个分布（KL/JS），而不是拟合一个点估计框。

- Teacher 输出：$(\mu_x,\mu_y,\mu_w,\mu_h) + (\sigma_x,\sigma_y,\sigma_w,\sigma_h)$（或用离散 bins 的分布）
    
- Student 最小化：$KL( teacher_box_dist || student_box_dist )$
    
- 同时把无标注 loss 权重设为与不确定性反比：$w = 1/(σ+ε)$
    
**效果**：伪标签不准时不会“强行拉到错位置”，对小目标尤其稳。

---

## **方案 4：一类检测的“背景对比学习”（Hard Negative Contrast）**

**核心想法**：单类任务最难的常是“背景长得像目标”。你可以用无标注图自动挖 hard negatives，让特征更分离。
做法：
- 用 Teacher 在无标注图上找两类 patch：
    
    - **正样本 patch**：高 objectness 的小区域（可不需要框很准）
        
    - **难负样本 patch**：objectness 中等但 NMS 后被抑制/或在目标附近、最容易误检的区域
        
	
- 在 backbone/neck 上做对比损失：InfoNCE( pos vs hard_neg )
    
- 同时正常跑少量监督检测 loss
    
**优点**：对“标注少 + 小目标假阳性多”很管用，因为你在用无标注数据专门学“别把背景当目标”。